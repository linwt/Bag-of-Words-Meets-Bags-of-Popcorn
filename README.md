# 项目思路
## CountVectorizer
- 将处理后的文本数据转成词频矩阵，设置5000个最高词频的单词作为特征，统计每段评论中每个词的出现次数作为一个向量
```
array([[1, 0, 2, ..., 0, 0, 0],  
       [0, 5, 0, ..., 7, 0, 0],  
       ...,  
       [0, 0, 3, ..., 4, 0, 0],  
       [4, 6, 0, ..., 0, 8, 0]]) 
```
- 用随机森林模型训练、预测
## TfidfVectorizer
- 将处理后的文本数据转成词频权重矩阵。TfidfTransformer用于统计vectorizer中每个词语的TFIDF值，TfidfVectorizer相当于CountVectorizer配合TfidfTransformer使用的效果。
```
array([[0.85, 0., 0.65, ..., 0., 0., 0.],
       [0., 0.74, 0., ..., 0.24, 0., 0.],
       ...,
       [0., 0., 0.53, ..., 0., 0.22, 0.],
       [0.89, 0., 0., ..., 0., 0., 0.36]])
```
- 用逻辑回归模型训练、预测
## Word2Vec
- 将处理后的文本数据转成词向量矩阵。设置最高词频的300个词作为特征，对每个词进行统计，统计所有句子中该词出现时作为特征的词也同时出现的次数作为一个向量，两个向量相似的词为相似词。
```
array([[3, 0, 0, ..., 2, 1, 1],  
       [0, 2, 4, ..., 0, 0, 0],  
       ...,  
       [0, 2, 4, ..., 0, 0, 0],  
       [0, 1, 0, ..., 0, 1, 1]]) 
```
- 从词向量到段落，处理方式一：向量平均  
将处理后的文本数据转成向量平均矩阵。最高词频的300个词作为特征，累加每段评论中包含在词向量矩阵的单词向量，最后取平均作为一个向量
```
array([[2, 0.5, 0, ..., 2.5, 0, 0],  
       [0, 1, 0, ..., 2, 0, 0.33],  
       ...,  
       [0, 0, 0.4, ..., 0, 0.8, 2],  
       [0, 0.2, 0, 10..., 0, 1, 0]]) 
```
- 从词向量到段落，处理方式二：聚类  
用KMeans算法将词向量矩阵中相似词归类，创建质心矩阵，所有类别作为特征，每段评论中的单词属于哪一类别则该位置加1，最后作为一个向量
```
array([[2, 0, 7, ..., 0, 0, 0],  
       [0, 4, 0, ..., 0, 5, 0],  
       ...,  
       [0, 0, 1, ..., 0, 6, 0],  
       [0, 0, 3, ..., 0, 2, 0]]) 
```
- 用随机森林模型训练、预测
